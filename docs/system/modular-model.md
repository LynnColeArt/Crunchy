
# Data Modelling Specification

**Version 0.3.4**

## Table of Contents

1. [Overview](#overview)
2. [Supported Notation Formats](#supported-notation-formats)
   - [MusicXML](#musicxml)
   - [MuseScore JSON](#musescore-json)
   - [MIDI](#midi)
3. [Global Serialization Configuration](#global-serialization-configuration)
4. [Instrument Configuration Schema](#instrument-configuration-schema)
5. [Core Structure](#core-structure)
   - [Base Score Format](#base-score-format)
6. ["Dumb Compiler" Principle](#dumb-compiler-principle)
7. [Pattern and Condition Declarations](#pattern-and-condition-declarations)
8. [MPE Parameter Mapping Requirements](#mpe-parameter-mapping-requirements)
9. [Playstyles](#playstyles)
   - [Playstyle Precedence](#playstyle-precedence)
   - [Playstyle Inheritance](#example-playstyle-inheritance)
   - [Playstyle Conflict Resolution](#playstyle-conflict-resolution)
10. [Vocal Synthesis with Syllable-Level Representation](#vocal-synthesis-with-syllable-level-representation)
    - [Standardized Expression Validation](#standardized-expression-validation)
    - [Syllable-Level Representation Example](#example-syllable-level-representation)
11. [Regular Expression Rules](#regular-expression-rules)
    - [Tuning Validation Example](#example-1-tuning-validation)
    - [Multi-Instrument Validation Example](#example-2-advanced-multi-instrument-validation)
12. [Version History](#version-history)
13. [Acknowledgments](#acknowledgments)

---

## Overview

This document outlines a modular framework for encoding musical information in JSON format. The specification is designed to capture both traditional notation and performance data while maintaining format independence. This approach is intended to support mid-level developers, senior developers, and technically minded musicians who are comfortable working with structured data.

---

## Supported Notation Formats

This specification supports a range of input formats, ensuring broad compatibility and flexibility in music processing. The following formats are currently supported:

### MusicXML

- **Description**: A widely-used standard for representing Western musical notation.
- **Strengths**: High level of detail, including articulations and dynamics.
- **Limitations**: Complex to parse due to its verbosity.

### MuseScore JSON

- **Description**: A lightweight format generated by MuseScore for representing musical scores.
- **Strengths**: Compact and human-readable.
- **Limitations**: Less widely supported compared to MusicXML.

### MIDI

- **Description**: A performance-focused format capturing note data, velocities, and timing.
- **Strengths**: Universally supported by digital audio workstations (DAWs).
- **Limitations**: Lacks detailed notation information like articulations or dynamics.

---

## Global Serialization Configuration

```json
{
  "serialization_config": {
    "version": "0.3.4",
    "compatibility": {
      "musicxml": true,
      "midi": true,
      "musescore": true
    },
    "error_reporting": {
      "level": "comprehensive",
      "format": "json",
      "include_context": true
    }
  }
}
```

---

## Instrument Configuration Schema

```json
{
  "instrument": {
    "name": "Violin",
    "version": "0.3.4",
    "serialization_config": {
      "compatibility": {
        "musicxml": true,
        "midi": true,
        "musescore": true
      },
      "error_reporting": {
        "level": "comprehensive",
        "format": "json",
        "include_context": true
      }
    },
    "metadata": {
      "family": "string",
      "range": {
        "lowest": "G3",
        "highest": "A7"
      }
    }
  }
}
```

---

## Core Structure

### Base Score Format

The base score defines the metadata, structure, and parts of a musical composition. This representation aims to provide flexibility while maintaining clarity for potential use cases.

```json
{
  "score": {
    "metadata": {
      "title": "Example Score",
      "tickResolution": 960,
      "initialTempo": 120,
      "initialTimeSignature": {
        "numerator": 4,
        "denominator": 4
      }
    },
    "structure": [
      {
        "section": "verse",
        "startMeasure": 1,
        "endMeasure": 4,
        "lyrics": [
          {
            "text": "First",
            "timing": {"measure": 1, "parts": 0}
          },
          {
            "text": "verse",
            "timing": {"measure": 1, "parts": 1}
          }
        ]
      },
      {
        "section": "chorus",
        "startMeasure": 5,
        "endMeasure": 8
      }
    ],
    "parts": []
  }
}
```

---

## "Dumb Compiler" Principle

To ensure simplicity and maintainability, all behaviors and patterns defined in `.logic` files must compile into standard MPE-compatible MIDI messages without requiring complex code execution. This principle guarantees:

- Declarative pattern definitions.
- Full compliance with MIDI/MPE standards.
- Minimal computational overhead.

---

## Pattern and Condition Declarations

`.logic` files support the declaration of repeatable patterns and conditional behaviors. Example:

```json
{
  "behaviors": {
    "BluesRiff": {
      "repeat": {
        "count": 4,
        "pattern": {
          "mpe_parameters": {
            "attack": [
              {"time": 0, "value": 100},
              {"time": 0.25, "value": 80},
              {"time": 0.5, "value": 90}
            ]
          }
        }
      }
    }
  }
}
```

---

## MPE Parameter Mapping Requirements

Behavioral logic must explicitly map to standard MPE parameters. This includes:

- Defined MIDI channels (1-16).
- Control Change (CC) numbers within the 0-127 range.
- Clear value ranges for each parameter.

---

## Playstyles

Playstyles modify the interpretation and playback of musical compositions. They can be applied globally, at the layer level, or to individual notes.

### Playstyle Precedence

To resolve overlapping playstyles, the following precedence order is applied:

1. **Note-specific Playstyle** (Highest Priority): Applied directly to the note.
2. **Layer Playstyle**: Applied to all notes in the layer unless overridden by note-specific playstyles.
3. **Global Playstyle** (Lowest Priority): Applied across all layers and notes unless overridden by layer or note-specific playstyles.

### Example: Playstyle Inheritance

```json
{
  "timeline": {
    "globalPlaystyle": "default",
    "layers": [
      {
        "playstyle": "rock_rhythm",
        "notes": [
          {
            "pitch": "E4",
            "playstyle": "power_chord",
            "mpeModifiers": {
              "attack": 110,
              "pressure": 75
            }
          },
          {
            "pitch": "B3",
            "inherit_playstyle": true,
            "mpeModifiers": {
              "attack": 90
            }
          }
        ]
      }
    ]
  }
}
```

### Playstyle Conflict Resolution

- **Precedence**: Note > Layer > Global
- **Explicit Inheritance**: Use `"inherit_playstyle": true` to adopt parent playstyle.
- **Nested Modifier Application**: Applies additional modifications while retaining inherited attributes.

---

## Vocal Synthesis with Syllable-Level Representation

Vocal synthesis supports syllable-level precision, enabling nuanced playback and synthesis of vocal lines. Here is an example using the text: "It's a hot day on Mars, and all the passing cars."

### Standardized Expression Validation

Expression parameters are validated with the following standard ranges:

```json
{
  "vocalExpressionValidation": {
    "intensity": {
      "type": "float",
      "min": 0.0,
      "max": 1.0,
      "default": 0.5
    },
    "vibrato": {
      "type": "float", 
      "min": 0.0,
      "max": 0.5,
      "default": 0.1
    }
  }
}
```

### Example: Syllable-Level Representation

This example illustrates the timing and expression mapping for the text "It's a hot day on Mars, and all the passing cars":

```json
{
  "vocalLayer": {
    "id": "vocal1",
    "type": "vocal",
    "lyrics": [
      {
        "syllable": "It's",
        "timing": {"start": "1.1.0", "duration": "0.5.0"},
        "expression": {"intensity": 0.7, "vibrato": 0.2}
      },
      {
        "syllable": "a",
        "timing": {"start": "1.1.5", "duration": "0.25.0"},
        "expression": {"intensity": 0.6, "vibrato": 0.1}
      },
      {
        "syllable": "hot",
        "timing": {"start": "1.1.75", "duration": "0.25.0"},
        "expression": {"intensity": 0.8, "vibrato": 0.3}
      },
      {
        "syllable": "day",
        "timing": {"start": "1.2.0", "duration": "0.5.0"},
        "expression": {"intensity": 0.7, "vibrato": 0.2}
      },
      {
        "syllable": "on",
        "timing": {"start": "1.2.5", "duration": "0.25.0"},
        "expression": {"intensity": 0.6, "vibrato": 0.1}
      },
      {
        "syllable": "Mars",
        "timing": {"start": "1.2.75", "duration": "0.25.0"},
        "expression": {"intensity": 0.9, "vibrato": 0.4}
      },
      {
        "syllable": "and",
        "timing": {"start": "1.3.0", "duration": "0.5.0"},
        "expression": {"intensity": 0.7, "vibrato": 0.2}
      },
      {
        "syllable": "all",
        "timing": {"start": "1.3.5", "duration": "0.25.0"},
        "expression": {"intensity": 0.6, "vibrato": 0.1}
      },
      {
        "syllable": "the",
        "timing": {"start": "1.3.75", "duration": "0.25.0"},
        "expression": {"intensity": 0.6, "vibrato": 0.1}
      },
      {
        "syllable": "passing",
        "timing": {"start": "2.1.0", "duration": "0.5.0"},
        "expression": {"intensity": 0.8, "vibrato": 0.3}
      },
      {
        "syllable": "cars",
        "timing": {"start": "2.1.5", "duration": "0.5.0"},
        "expression": {"intensity": 0.9, "vibrato": 0.4}
      }
    ]
  }
}
```

---

## Regular Expression Rules

Regular expressions (regex) provide a powerful mechanism for validating and shaping musical data within the system. They enable developers to define flexible rules for complex scenarios, such as ensuring valid instrument tunings or enforcing pitch ranges for specific instruments. Below are two illustrative examples and their high-level explanations.

### Example 1: Tuning Validation

This regex ensures that string instruments are tuned to valid pitches within standard ranges:

```json
{
  "rules": {
    "tuningRules": {
      "regex": "^[EADGB][#b]?[1-6]$",
      "errorMessage": "Invalid tuning."
    }
  }
}
```

#### Explanation

- **Use Case**: Ensuring tunings like "E2", "A3", or "D4" are valid for a guitar.
- **Pattern Breakdown**:
  - `^[EADGB]`: Matches the first character to valid string names (E, A, D, G, B).
  - `[\#b]?`: Allows optional sharps (#) or flats (b).
  - `[1-6]$`: Ensures the string number is within the range 1 to 6.

This ensures that musicians cannot input invalid tunings like "H3" or "A7" while maintaining flexibility for sharps and flats.

### Example 2: Advanced Multi-Instrument Validation

This regex expands validation for multiple instruments, including pitch ranges and techniques:

```json
{
  "instrumentValidation": {
    "violin": {
      "pitch_range": "^[CDEFGAB][#b]?[3-5]$",
      "valid_techniques": ["vibrato", "harmonics", "pizzicato"]
    },
    "guitar": {
      "pitch_range": "^[CDEFGAB][#b]?[2-6]$",
      "valid_techniques": ["bend", "hammer_on", "pull_off"],
      "tuning_rules": "^[EADGBE][#b]?[1-6]$"
    }
  }
}
```

#### Explanation

- **Use Case**: Validating both pitch ranges and techniques for instruments like violin and guitar.
- **Pattern Breakdown**:
  - `pitch_range`: Defines valid note ranges for each instrument.
  - `valid_techniques`: Lists techniques allowed for the instrument.
  - `tuning_rules`: Adds constraints for tuning configurations specific to the guitar.

This advanced validation supports comprehensive rule enforcement tailored to specific instruments.

---

## Version History

- **0.3.4**: Introduced global and instrument-level configuration schemas. Expanded examples and included detailed explanations for vocal synthesis, playstyles, and regular expressions. Formally introduced the "Dumb Compiler" principle for simplifying `.logic` file processing. Added Table of Contents.
- **0.3.3**: Added hybrid instrument definitions, expanded cultural-specific articulations, separated `.instrument` and `.logic` files, and formalized MPE requirements.
- **0.3.2**: Introduced vocal synthesis with syllable-level representation and detailed examples for modifiers, effects, timeline layering, and cultural-specific articulations.
- **0.3.1**: Introduced timeline concept, instruments, blends, and modifiers. (0.3.1 and 0.3.1b are effectively the same draft with minor iterative changes that were posted publicly.)
- **0.2.0**: Switched the representation language from Go to JSON because we realized natively compiling compositions into machine code wasn't going to be necessary for most compositions.

## Acknowledgments

This document has benefited from valuable feedback and contributions from Tim Simpson Jr., Michael Davis, Node Chomsky, Rich Fantasia, Gene The Machine, and Rachel M. Their expertise and collaboration have been instrumental in shaping this specification.

Their expertise and collaboration have been instrumental in making this specification a robust foundation for musical notation modeling. We thank the broader community for their continued support and engagement.
